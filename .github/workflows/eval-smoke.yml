name: 'Eval: Smoke Tests'

on:
  pull_request:
    paths:
      - 'Sources/VoxProviders/RewritePrompts.swift'
      - 'Sources/VoxCore/RewriteQualityGate.swift'
      - 'evals/**'
  workflow_dispatch:

jobs:
  eval:
    name: Rewrite Smoke Tests
    runs-on: ubuntu-latest
    permissions:
      pull-requests: write
      contents: read
    steps:
      - uses: actions/checkout@v4

      - uses: actions/setup-node@v4
        with:
          node-version: '22'

      - name: Cache Promptfoo
        uses: actions/cache@v4
        with:
          path: ~/.promptfoo
          key: ${{ runner.os }}-promptfoo-${{ hashFiles('evals/promptfooconfig.yaml') }}
          restore-keys: ${{ runner.os }}-promptfoo-

      - name: Install promptfoo
        run: npm install -g promptfoo@latest

      - name: Run Evaluation
        # promptfoo exits 100 when any test fails. Don't let that fail the job —
        # the Check Results step is the actual gate with known-failure baseline.
        continue-on-error: true
        run: |
          promptfoo eval \
            --config evals/promptfooconfig.yaml \
            --no-progress-bar \
            -o evals/output/results.json
        env:
          OPENROUTER_API_KEY: ${{ secrets.OPENROUTER_API_KEY }}
          OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}

      - name: Generate Report
        run: node evals/scripts/format-report.js < evals/output/results.json > evals/output/report.md

      - name: Post PR Comment
        if: always() && github.event_name == 'pull_request'
        env:
          GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        run: |
          # Delete previous eval comment if it exists
          COMMENT_ID=$(gh api \
            repos/${{ github.repository }}/issues/${{ github.event.pull_request.number }}/comments \
            --jq '.[] | select(.body | startswith("## ")) | select(.body | contains("Rewrite Eval Report")) | .id' \
            2>/dev/null | head -1)
          if [ -n "$COMMENT_ID" ]; then
            gh api repos/${{ github.repository }}/issues/comments/$COMMENT_ID -X DELETE 2>/dev/null || true
          fi
          # Post new comment
          gh pr comment ${{ github.event.pull_request.number }} --body-file evals/output/report.md

      - name: Upload Results
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: eval-smoke-${{ github.run_number }}
          path: evals/output/
          retention-days: 30

      - name: Check Results
        if: always()
        run: |
          # Known failures (2): haiku injection (model writes haiku instead of
          # rewriting) and system prompt leak (Gemini Flash Lite vulnerable to
          # direct extraction). Both are model vulnerabilities, not prompt regressions.
          # Fail CI if failures exceed this baseline — that's a regression.
          KNOWN_FAILURES=2
          FAILED=$(node -e "const d = require('./evals/output/results.json'); const f = d.results.results.filter(r => !r.success).length; process.stdout.write(String(f))")
          TOTAL=$(node -e "const d = require('./evals/output/results.json'); process.stdout.write(String(d.results.results.length))")
          echo "Eval results: ${FAILED}/${TOTAL} failed (known baseline: ${KNOWN_FAILURES})"
          if [ "$FAILED" -gt "$KNOWN_FAILURES" ]; then
            echo "::error::Regression detected — ${FAILED} failures exceeds known baseline of ${KNOWN_FAILURES}"
            exit 1
          fi
