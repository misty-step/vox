## Purpose
The `Sources` directory contains the modular architecture of the Vox macOS application, encompassing the application entry point, core processing logic, and specialized frameworks. It integrates audio capture, speech-to-text (STT) services, and LLM-based text refinement into a unified dictation pipeline. The directory also includes diagnostic tools, performance benchmarking suites, and macOS-specific system integrations for user interface and hardware management.

## Key Roles
- **VoxApp & VoxAppKit**: Manage the application lifecycle, initialization, and high-level orchestration via the `AppDelegate`.
- **VoxCore**: Defines foundational protocols, error types, and decorators for STT, rewriting, and concurrency control.
- **VoxMac**: Implements macOS-specific infrastructure for audio recording, AES-GCM encryption, system-wide hotkeys, and clipboard manipulation.
- **VoxPipeline & VoxProviders**: Orchestrate the end-to-end transformation of audio to refined text using local frameworks and cloud-based providers like Deepgram and OpenRouter.
- **VoxSession**: Controls the state machine for dictation sessions, managing transitions between idle, recording, and processing phases.
- **VoxUI**: Provides the SwiftUI and AppKit interface components, including the status bar menu, onboarding flow, and settings management.
- **VoxBenchmarks & VoxPerfAudit**: Execute performance evaluations and audits to measure latency, cost, and quality across different models and pipeline stages.
- **VoxDiagnostics**: Facilitates structured event logging, log rotation, and the generation of diagnostic export bundles.

## Dependencies and Caveats
- Depends on system frameworks including `AppKit`, `AVFoundation`, `CoreAudio`, `Carbon`, `Speech`, and `CryptoKit`.
- Requires the `/usr/bin/afconvert` and `/usr/bin/ditto` system utilities for audio encoding and diagnostic archiving.
- Integrates with third-party APIs including Deepgram, ElevenLabs, Gemini, and OpenRouter for STT and text rewriting.
- Uses the macOS Keychain for secure API key storage and `UserDefaults` for persisting user preferences and window positions.
- Requires system-level permissions for Microphone and Accessibility to enable audio capture and simulated keystrokes for text insertion.
- Supports both real-time streaming via WebSockets and batch processing workflows for transcription.
- Implements fallback mechanisms that transition to local Apple Speech recognition if cloud-based providers are unavailable or fail.
- Configuration and feature flags are managed through environment variables such as `VOX_STT_ROUTING`, `VOX_AUDIO_BACKEND`, and `VOX_PERF_INGEST_URL`.