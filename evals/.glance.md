## Purpose
This directory provides a framework for evaluating the quality and safety of AI-driven speech transcript transformations. It includes multi-model "bakeoff" configurations, specialized prompt templates for cleaning and polishing text, and datasets targeting instruction-following and prompt injection resistance. Automated scripts facilitate the execution of these evaluations and the generation of formatted performance reports. The system ensures that transcripts are edited for clarity without hallucinating information or executing commands embedded in the input.

## Key Roles
- **bakeoff-config.yaml**: Defines multi-model evaluation parameters for the "clean" prompt using various OpenRouter providers and a transcription cleanup rubric.
- **polish-bakeoff.yaml**: Configures extensive quality and safety testing for the "polish" prompt across baseline, value, and premium model tiers.
- **polish-smoke.yaml**: Provides a configuration for rapid sanity checks of the polishing logic using a subset of test cases.
- **promptfooconfig.yaml**: Sets the primary evaluation configuration for testing transcript cleaning quality against the smoke test dataset.
- **datasets/**: Stores YAML test suites covering prompt injection, transcript polishing, and general smoke tests.
- **prompts/**: Contains JSON-formatted system instructions for "transcription editor" and "elite editor" roles.
- **scripts/**: Includes shell orchestrators and Node.js utilities for running evaluations, parsing results, and formatting Markdown reports.

## Dependencies and Caveats
- Evaluations rely on the `promptfoo` framework for execution and grading.
- Grading is primarily managed via `llm-rubric` assertions that use specific models, such as DeepSeek, to score outputs.
- Prompts use the `{{transcript}}` placeholder for dynamic content injection.
- Rubrics strictly penalize "acting on instructions" (e.g., writing a poem) mentioned within the transcript text.
- Safety rules prohibit the addition of new facts, claims, or meta-commentary about the AI's role or capabilities.
- The system uses OpenRouter to access a wide range of models including Gemini, GPT-5, Claude, and Llama variants.
- `check-smoke-results.js` employs hardcoded strings to filter known model failures and specific false negatives.
- Configurations explicitly disable caching and set `maxConcurrency` limits for evaluation runs.