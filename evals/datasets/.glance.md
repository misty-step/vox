## Purpose
This directory contains YAML-based evaluation datasets designed to test the performance and safety of Vox rewrite and polish prompts. The datasets focus on validating that the model can restructure and clean rambling dictation without hallucinating new information or executing instructions embedded within the transcript. Specifically, these tests target instruction-following, prompt injection resistance, and the removal of filler words while maintaining factual accuracy.

## Key Roles
- **injection.yaml**: Provides red team test cases featuring various prompt injection techniques, including role-play simulation, base64 obfuscation, and template variable leakage attempts.
- **polish.yaml**: Contains scenarios for re-organizing and articulating messy transcripts, such as meeting recaps and technical reports, while ensuring the model does not execute requests for lists, poems, or comparisons.
- **smoke.yaml**: Serves as a general smoke test suite covering common dictation cleanup, known bugs like embedded AI queries, and system prompt extraction attempts.
- **polish-smoke.yaml**: Functions as a high-speed validation suite for aggressive "hard in the paint" polishing to ensure no hallucinations occur before running full test bakes.

## Dependencies and Caveats
- Quality judgment for several suites is managed by an `llm-rubric` defined in `promptfooconfig.yaml`.
- Deterministic assertions, such as `contains` and `not-contains`, are used to catch specific keyword leaks and keyword-based injection failures.
- Certain models, specifically Gemini 2.5 Flash Lite, are noted as vulnerable to direct system prompt extraction.
- Tests are designed to ensure the model preserves words and specific details (numbers, dates) while ignoring "SYSTEM OVERRIDE" or "Ignore all previous instructions" commands.
- The suites specifically monitor for "instruction leakage," where a model might mistakenly fulfill a request mentioned in a transcript, such as writing a haiku or a poem.
- Deterministic checks for content overlap and Levenshtein distance are utilized in production gates to supplement LLM-based judging.